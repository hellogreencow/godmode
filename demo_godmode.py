#!/usr/bin/env python3
"""
GODMODE Demo Script

Demonstrates the full GODMODE system with realistic examples.
"""

import asyncio
import json
from typing import List, Dict, Any

def print_header(title: str):
    """Print a formatted header."""
    print(f"\n{'='*60}")
    print(f"🧠 {title}")
    print('='*60)

def print_section(title: str):
    """Print a formatted section."""
    print(f"\n📋 {title}")
    print('-' * 40)

class GodmodeDemo:
    """GODMODE demonstration with realistic examples."""
    
    def __init__(self):
        self.question_counter = 0
        self.session_history = []
    
    def next_id(self) -> str:
        """Generate next question ID."""
        self.question_counter += 1
        return f"Q{self.question_counter}"
    
    async def analyze_question(self, question: str, context: str = None) -> Dict[str, Any]:
        """Analyze a question using GODMODE methodology."""
        
        print_header(f"ANALYZING: {question}")
        
        if context:
            print(f"📝 Context: {context}")
        
        # Phase 1: Extract premises (backward reasoning)
        print_section("PHASE 1: BACKWARD REASONING (Prior Questions)")
        
        premises = self.extract_premises(question)
        priors = []
        
        for i, premise in enumerate(premises):
            prior = {
                "id": f"QP{i+1}",
                "text": premise,
                "level": i + 1,
                "cognitive_move": ["define", "scope", "quantify", "compare"][i % 4],
                "builds_on": [f"QP{i}"] if i > 0 else [],
                "delta_nuance": f"Level {i+1}: {['Establishes foundation', 'Adds boundaries', 'Introduces metrics', 'Enables comparison'][i % 4]}",
                "expected_info_gain": max(0.3, 0.9 - i * 0.15),
                "confidence": max(0.2, 0.8 - i * 0.1)
            }
            priors.append(prior)
            
            print(f"  {prior['id']}: {prior['text']}")
            print(f"     ├─ Cognitive Move: {prior['cognitive_move']}")
            print(f"     ├─ Info Gain: {prior['expected_info_gain']:.2f}")
            print(f"     └─ Builds On: {prior['builds_on'] if prior['builds_on'] else 'None'}")
        
        # Phase 2: Generate scenario lanes (forward reasoning)
        print_section("PHASE 2: FORWARD REASONING (Scenario Lanes)")
        
        scenarios = await self.generate_scenarios(question, context)
        
        for scenario in scenarios:
            print(f"  🚀 {scenario['id']}: {scenario['name']}")
            print(f"     Description: {scenario['description']}")
            print(f"     Questions ({len(scenario['questions'])}):")
            
            for q in scenario['questions']:
                print(f"       {q['id']}: {q['text']}")
                print(f"         ├─ Level: {q['level']}, Move: {q['cognitive_move']}")
                print(f"         └─ Info Gain: {q['expected_info_gain']:.2f}")
        
        # Phase 3: Generate ontology
        print_section("PHASE 3: ONTOLOGY EXTRACTION")
        
        entities, relations = self.extract_ontology(question, context)
        
        print("  Entities:")
        for entity in entities:
            print(f"    • {entity['name']} ({entity['type']}) - confidence: {entity['confidence']:.2f}")
        
        print("  Relations:")
        for relation in relations:
            print(f"    • {relation['subj']} --{relation['pred']}--> {relation['obj']}")
        
        # Phase 4: Generate response
        print_section("PHASE 4: RESPONSE GENERATION")
        
        chat_reply = self.generate_chat_reply(priors, scenarios)
        print(f"💬 Chat Reply: {chat_reply}")
        
        # Create comprehensive response
        response = {
            "chat_reply": chat_reply,
            "graph_update": {
                "current_question": question,
                "priors": priors,
                "scenarios": scenarios,
                "threads": [
                    {
                        "thread_id": "T1",
                        "origin_node_id": priors[0]["id"] if priors else "Q1",
                        "path": [priors[0]["id"]] if priors else ["Q1"],
                        "status": "active",
                        "summary": f"Starting analysis of: {question[:50]}..."
                    }
                ],
                "meta": {
                    "version": "1.0",
                    "budgets_used": {"beam_width": 4, "depth_back": 4, "depth_fwd": 5},
                    "notes": "Generated by GODMODE demo"
                }
            },
            "ontology_update": {
                "entities": entities,
                "relations": relations,
                "mappings": []
            }
        }
        
        self.session_history.append(response)
        return response
    
    def extract_premises(self, question: str) -> List[str]:
        """Extract hidden premises from the question."""
        premises = []
        question_lower = question.lower()
        
        # Rule-based premise extraction
        if any(word in question_lower for word in ["best", "optimal", "should"]):
            premises.append("What criteria define 'optimal' or 'best' in this context?")
        
        if any(word in question_lower for word in ["improve", "increase", "enhance"]):
            premises.append("What is the current baseline we're improving from?")
        
        if any(word in question_lower for word in ["how", "what way", "approach"]):
            premises.append("What methods and approaches are available to us?")
        
        if any(word in question_lower for word in ["team", "organization", "company"]):
            premises.append("What are our organizational constraints and capabilities?")
        
        # Always include fundamental premises
        premises.extend([
            "What does success look like for this initiative?",
            "What are the key risks and potential obstacles?",
            "What resources (time, budget, people) are available?",
            "What are the downstream consequences of different approaches?"
        ])
        
        return premises[:4]  # Limit to 4 for clarity
    
    async def generate_scenarios(self, question: str, context: str = None) -> List[Dict[str, Any]]:
        """Generate scenario lanes for forward reasoning."""
        
        # Simulate async processing
        await asyncio.sleep(0.1)
        
        scenarios = [
            {
                "id": "S-A",
                "name": "Direct Path",
                "description": "Most straightforward and efficient approach",
                "focus": "efficiency"
            },
            {
                "id": "S-B",
                "name": "Comprehensive",
                "description": "Thorough exploration of all alternatives",
                "focus": "completeness"
            },
            {
                "id": "S-C",
                "name": "Risk-Managed",
                "description": "Conservative approach with risk mitigation",
                "focus": "safety"
            },
            {
                "id": "S-D",
                "name": "Innovation-First",
                "description": "Creative and novel approach prioritizing innovation",
                "focus": "innovation"
            }
        ]
        
        # Generate questions for each scenario
        for scenario in scenarios:
            questions = []
            focus = scenario["focus"]
            lane_id = scenario["id"][-1]
            
            # Level 1: Define
            questions.append({
                "id": f"Q{lane_id}1",
                "text": f"How do we define success for this {focus}-focused approach?",
                "level": 1,
                "cognitive_move": "define",
                "builds_on": [],
                "delta_nuance": f"Establishes {focus} success criteria",
                "expected_info_gain": 0.8,
                "confidence": 0.7,
                "natural_end": False
            })
            
            # Level 2: Scope
            questions.append({
                "id": f"Q{lane_id}2",
                "text": f"What are the boundaries and constraints for this {focus} approach?",
                "level": 2,
                "cognitive_move": "scope",
                "builds_on": [f"Q{lane_id}1"],
                "delta_nuance": f"Defines {focus} scope boundaries",
                "expected_info_gain": 0.6,
                "confidence": 0.6,
                "natural_end": False
            })
            
            # Level 3: Quantify
            questions.append({
                "id": f"Q{lane_id}3",
                "text": f"How do we measure and track progress on this {focus} approach?",
                "level": 3,
                "cognitive_move": "quantify",
                "builds_on": [f"Q{lane_id}2"],
                "delta_nuance": f"Introduces {focus} metrics",
                "expected_info_gain": 0.5,
                "confidence": 0.5,
                "natural_end": False
            })
            
            # Level 4: Compare
            questions.append({
                "id": f"Q{lane_id}4",
                "text": f"How does this {focus} approach compare to alternatives?",
                "level": 4,
                "cognitive_move": "compare",
                "builds_on": [f"Q{lane_id}3"],
                "delta_nuance": f"Compares {focus} trade-offs",
                "expected_info_gain": 0.4,
                "confidence": 0.4,
                "natural_end": False
            })
            
            # Level 5: Decide (natural ending)
            questions.append({
                "id": f"Q{lane_id}5",
                "text": f"Should we proceed with this {focus} approach?",
                "level": 5,
                "cognitive_move": "decide",
                "builds_on": [f"Q{lane_id}4"],
                "delta_nuance": f"Decision point for {focus} approach",
                "expected_info_gain": 0.3,
                "confidence": 0.3,
                "natural_end": True
            })
            
            scenario["questions"] = questions
        
        return scenarios
    
    def extract_ontology(self, question: str, context: str = None) -> tuple[List[Dict], List[Dict]]:
        """Extract entities and relations from question and context."""
        
        entities = []
        relations = []
        text = question + (" " + context if context else "")
        text_lower = text.lower()
        
        # Extract entities based on keywords
        entity_patterns = {
            "customer": ("concept", 0.9),
            "satisfaction": ("metric", 0.8),
            "team": ("org", 0.9),
            "company": ("org", 0.9),
            "revenue": ("metric", 0.9),
            "market": ("place", 0.8),
            "product": ("product", 0.9),
            "user": ("person", 0.8),
            "process": ("concept", 0.7),
            "strategy": ("concept", 0.8)
        }
        
        entity_id = 1
        for keyword, (entity_type, confidence) in entity_patterns.items():
            if keyword in text_lower:
                entities.append({
                    "id": f"E{entity_id}",
                    "name": keyword.title(),
                    "type": entity_type,
                    "aliases": [],
                    "confidence": confidence
                })
                entity_id += 1
        
        # Extract simple relations
        relation_id = 1
        if "improve" in text_lower and "customer" in text_lower:
            relations.append({
                "id": f"R{relation_id}",
                "subj": "E1",  # Assuming first entity
                "pred": "needs_improvement",
                "obj": "satisfaction_level",
                "confidence": 0.7,
                "hypothesis": True,
                "evidence": []
            })
            relation_id += 1
        
        return entities, relations
    
    def generate_chat_reply(self, priors: List[Dict], scenarios: List[Dict]) -> str:
        """Generate concise chat reply."""
        
        reply_parts = []
        
        if priors:
            # Reference top 2 priors by info gain
            top_priors = sorted(priors, key=lambda p: p['expected_info_gain'], reverse=True)[:2]
            prior_refs = [f"**{p['id']}** ({p['cognitive_move']})" for p in top_priors]
            reply_parts.append(f"Start with {', '.join(prior_refs)}")
        
        if scenarios:
            # Reference top 2 scenarios
            top_scenarios = scenarios[:2]
            scenario_refs = [f"**{s['id']}** ({s['name']})" for s in top_scenarios]
            reply_parts.append(f"then explore {', '.join(scenario_refs)}")
        
        return ". ".join(reply_parts) + "."


async def run_demo():
    """Run the GODMODE demonstration."""
    
    print_header("GODMODE - Superhuman Question Foresight Engine")
    print("🎯 Tagline: 'See the questions before you ask them.'")
    print("\nThis demo shows GODMODE analyzing complex questions using:")
    print("• Backward reasoning (PRIOR ladders)")
    print("• Forward reasoning (FUTURE scenarios)")
    print("• Ontology extraction")
    print("• Structured response generation")
    
    demo = GodmodeDemo()
    
    # Demo questions
    demo_questions = [
        {
            "question": "How should we improve customer satisfaction for our SaaS product?",
            "context": "We're a B2B SaaS company with 500+ enterprise customers, currently at 7.2/10 satisfaction score"
        },
        {
            "question": "What's the best strategy to scale our engineering team from 15 to 50 people?",
            "context": "Fast-growing startup, $10M Series A, need to 3x product development velocity"
        },
        {
            "question": "Should I transition from software engineering to product management?",
            "context": "5 years as senior engineer, interested in strategy and user experience"
        }
    ]
    
    for i, demo_data in enumerate(demo_questions, 1):
        print(f"\n{'🔥' * 20} DEMO QUESTION {i} {'🔥' * 20}")
        
        response = await demo.analyze_question(
            demo_data["question"],
            demo_data["context"]
        )
        
        # Show summary
        print_section("SUMMARY")
        graph = response["graph_update"]
        print(f"✅ Generated {len(graph['priors'])} prior questions")
        print(f"✅ Created {len(graph['scenarios'])} scenario lanes")
        print(f"✅ Extracted {len(response['ontology_update']['entities'])} entities")
        print(f"✅ Chat reply: {response['chat_reply']}")
        
        if i < len(demo_questions):
            print("\n" + "⏱️  " * 20)
            await asyncio.sleep(1)  # Pause between demos
    
    # Final summary
    print_header("DEMO COMPLETE")
    print(f"🎉 Successfully analyzed {len(demo_questions)} complex questions")
    print(f"📊 Generated {sum(len(r['graph_update']['priors']) for r in demo.session_history)} total prior questions")
    print(f"🚀 Created {sum(len(r['graph_update']['scenarios']) for r in demo.session_history)} total scenario lanes")
    print(f"🧠 Extracted {sum(len(r['ontology_update']['entities']) for r in demo.session_history)} total entities")
    
    print("\n🔮 GODMODE demonstrates:")
    print("✅ Systematic question decomposition")
    print("✅ Multiple scenario exploration")
    print("✅ Knowledge graph construction")
    print("✅ Structured decision support")
    print("✅ Scalable reasoning architecture")
    
    print(f"\n{'🧠' * 20} GODMODE {'🧠' * 20}")
    print("Ready to see the questions before you ask them!")


if __name__ == "__main__":
    asyncio.run(run_demo())